{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa942474",
   "metadata": {},
   "source": [
    "## 1、简述BLEU分数的计算原理。BLEU主要通过对生成文本和参考文本的n-gram进行匹配来衡量相似度，结合代码解析sentence_bleu函数在BLEU分数计算中的作用，并说明如何利用smoothing_function对低频词进行平滑处理以提升评估稳定性。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575a7e50",
   "metadata": {},
   "source": [
    "BLEU（Bilingual Evaluation Understudy）分数是一种广泛用于评估机器翻译或文本生成质量的自动指标，其核心思想是通过比较生成文本（candidate）与一个或多个参考文本（reference）之间的 **n-gram 重合度** 来衡量相似性。\n",
    "\n",
    "---\n",
    "\n",
    "### 一、BLEU 分数的计算原理\n",
    "\n",
    "BLEU 分数由以下两个主要部分组成：\n",
    "\n",
    "#### 1. **n-gram 精度（Modified n-gram Precision）**\n",
    "\n",
    "对于每个 n（通常取 1 到 4），计算生成句子中每个 n-gram 在参考句中出现的次数上限（避免重复匹配）。具体为：\n",
    "\n",
    "$\n",
    "\\text{Precision}_n = \\frac{\\sum_{\\text{n-gram} \\in \\text{candidate}} \\min(\\text{count}_{\\text{candidate}}(\\text{n-gram}), \\max_{\\text{ref} \\in \\text{references}} \\text{count}_{\\text{ref}}(\\text{n-gram}))}{\\sum_{\\text{n-gram} \\in \\text{candidate}} \\text{count}_{\\text{candidate}}(\\text{n-gram})}\n",
    "$\n",
    "\n",
    "对 n=1 到 N（如 N=4）取几何平均：\n",
    "\n",
    "$\n",
    "\\text{BP} \\times \\exp\\left( \\sum_{n=1}^{N} w_n \\log \\text{Precision}_n \\right)\n",
    "$\n",
    "\n",
    "其中 ($ w_n = 1/N $) 通常为均匀权重。\n",
    "\n",
    "#### 2. **简短惩罚（Brevity Penalty, BP）**\n",
    "\n",
    "防止过短的生成文本获得高分：\n",
    "\n",
    "$\n",
    "\\text{BP} = \n",
    "\\begin{cases}\n",
    "1 & \\text{if } c > r \\\\\n",
    "\\exp(1 - r/c) & \\text{if } c \\leq r\n",
    "\\end{cases}\n",
    "$\n",
    "\n",
    "其中：\n",
    "- ($ c $) 是生成句长度\n",
    "- ($ r $) 是参考句中最接近 ($ c $) 的长度（或多个参考句的最优有效长度）\n",
    "\n",
    "---\n",
    "\n",
    "### 二、`sentence_bleu` 函数的作用（NLTK 实现）\n",
    "\n",
    "在 Python 的 `nltk.translate.bleu_score` 模块中，`sentence_bleu` 是计算单句 BLEU 分数的便捷接口。\n",
    "\n",
    "#### 示例代码：\n",
    "\n",
    "```python\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "references = [['this', 'is', 'a', 'test'], ['this', 'is', 'test']]\n",
    "candidate = ['this', 'is', 'a', 'test']\n",
    "\n",
    "# 基础 BLEU（默认 n=4）\n",
    "bleu = sentence_bleu(references, candidate)\n",
    "print(f'BLEU: {bleu:.4f}')\n",
    "```\n",
    "\n",
    "**作用说明：**\n",
    "- `references`：一个或多个参考句（每个是 token 列表的列表）\n",
    "- `candidate`：生成句（token 列表）\n",
    "- 默认计算 BLEU-4（即 n=1,2,3,4 的几何平均）\n",
    "- 自动处理 n-gram 计数、截断匹配、简短惩罚等\n",
    "\n",
    "---\n",
    "\n",
    "### 三、平滑处理（SmoothingFunction）及其必要性\n",
    "\n",
    "#### 问题：\n",
    "当生成句中包含参考句未出现的 n-gram（尤其是高阶 n-gram，如 3-gram、4-gram）时，对应的 precision_n = 0，导致整个 BLEU 分数为 0（因为几何平均中有 log(0) → -∞）。\n",
    "\n",
    "#### 解决方案：\n",
    "使用 `SmoothingFunction` 对零频 n-gram 进行平滑，避免分数崩溃。\n",
    "\n",
    "#### NLTK 中的平滑方法（如 `method1`）：\n",
    "\n",
    "```python\n",
    "smoothie = SmoothingFunction().method1\n",
    "bleu_smooth = sentence_bleu(references, candidate, smoothing_function=smoothie)\n",
    "```\n",
    "\n",
    "**原理（以 method1 为例）：**\n",
    "- 对每个 n-gram 精度，若分子为 0，则加一个极小值（如 1），分母也相应调整\n",
    "- 实质是给未匹配的 n-gram 分配一个“伪计数”，使其精度不为 0\n",
    "- 常用方法还包括线性插值、加一平滑（Laplace）等\n",
    "\n",
    "#### 为什么能提升稳定性？\n",
    "- 避免因个别罕见词或新词导致整个 BLEU 为 0\n",
    "- 使 BLEU 在短句、低资源或开放域生成任务中更鲁棒\n",
    "- 更合理地反映部分匹配的语义相似性\n",
    "\n",
    "---\n",
    "\n",
    "### 总结\n",
    "\n",
    "| 组件 | 作用 |\n",
    "|------|------|\n",
    "| **n-gram 匹配** | 衡量词汇重合度 |\n",
    "| **Modified Precision** | 防止重复匹配膨胀分数 |\n",
    "| **Brevity Penalty** | 惩罚过短输出 |\n",
    "| **sentence_bleu** | 封装完整 BLEU 计算流程 |\n",
    "| **SmoothingFunction** | 避免零精度引起的分数崩溃，提升评估稳定性 |\n",
    "\n",
    "通过合理使用平滑策略，BLEU 能在实际应用中更公平、稳定地评估生成质量，尤其适用于短文本或词汇差异较大的场景。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed876e74",
   "metadata": {},
   "source": [
    "## 2、在计算ROUGE分数时，rouge1、rouge2、rougeL分别表示什么含义？使用rouge_scorer.RougeScorer计算这些分数时，如何通过分数的精确率、召回率和F1值来衡量生成文本和参考文本的覆盖度？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f72695",
   "metadata": {},
   "source": [
    "ROUGE（Recall-Oriented Understudy for Gisting Evaluation）是一组用于评估自动摘要或文本生成质量的指标，其核心思想是**通过 n-gram、词序列或最长公共子序列（LCS）的重合程度来衡量生成文本（candidate）与参考文本（reference）之间的相似性**。ROUGE 更侧重于**召回率（Recall）**，即参考文本中有多少内容被生成文本覆盖。\n",
    "\n",
    "---\n",
    "\n",
    "### 一、ROUGE-1、ROUGE-2、ROUGE-L 的含义\n",
    "\n",
    "| 指标        | 含义                                                                 |\n",
    "|-------------|----------------------------------------------------------------------|\n",
    "| **ROUGE-1** | 基于 **unigram（单个词）** 的重合度，衡量生成文本对参考文本中词汇的覆盖程度。 |\n",
    "| **ROUGE-2** | 基于 **bigram（连续两个词）** 的重合度，评估生成文本是否保留了参考文本中的局部词序和短语结构。 |\n",
    "| **ROUGE-L** | 基于 **最长公共子序列（Longest Common Subsequence, LCS）**，不要求连续但保持顺序，能捕捉句子级结构相似性，对词序更敏感且比 n-gram 更灵活。 |\n",
    "\n",
    "> 注意：ROUGE-L 中的 \"L\" 代表 **LCS**，不是 \"Long\"。\n",
    "\n",
    "---\n",
    "\n",
    "### 二、使用 `rouge_scorer.RougeScorer` 计算 ROUGE 分数\n",
    "\n",
    "Python 中常用 `rouge_scorer` 库（由 Google 开发）来计算 ROUGE。安装方式：\n",
    "\n",
    "```bash\n",
    "pip install rouge-scorer\n",
    "```\n",
    "\n",
    "#### 示例代码：\n",
    "\n",
    "```python\n",
    "from rouge_scorer import rouge_scorer\n",
    "\n",
    "# 初始化 scorer，指定要计算的 ROUGE 类型\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "reference = \"the cat sat on the mat\"\n",
    "candidate = \"the cat is on the mat\"\n",
    "\n",
    "scores = scorer.score(reference, candidate)\n",
    "\n",
    "# 打印各指标的 precision, recall, fmeasure\n",
    "for key, value in scores.items():\n",
    "    print(f\"{key}: P={value.precision:.4f}, R={value.recall:.4f}, F1={value.fmeasure:.4f}\")\n",
    "```\n",
    "\n",
    "输出示例：\n",
    "```\n",
    "rouge1: P=0.8571, R=0.8571, F1=0.8571\n",
    "rouge2: P=0.6667, R=0.6667, F1=0.6667\n",
    "rougeL: P=0.8333, R=0.8333, F1=0.8333\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 三、如何通过 P、R、F1 衡量覆盖度？\n",
    "\n",
    "ROUGE 对每个指标返回三个值：\n",
    "\n",
    "| 指标        | 含义                                                                 |\n",
    "|-------------|----------------------------------------------------------------------|\n",
    "| **Precision（P）** | 生成文本中有多少比例的 n-gram / LCS 出现在参考文本中 → **相关性**（避免冗余） |\n",
    "| **Recall（R）**    | 参考文本中有多少比例的 n-gram / LCS 被生成文本覆盖 → **覆盖度**（核心关注点） |\n",
    "| **F1-score**       | P 和 R 的调和平均，综合衡量生成质量                                  |\n",
    "\n",
    "#### 如何解读？\n",
    "- **高 Recall（R）**：说明生成文本较好地覆盖了参考内容（ROUGE 的设计初衷）。\n",
    "- **高 Precision（P）**：说明生成内容大多与参考相关，没有太多无关信息。\n",
    "- **高 F1**：在覆盖度和准确性之间取得良好平衡。\n",
    "\n",
    "> 在自动摘要任务中，通常更关注 **Recall**，因为目标是“尽可能包含参考摘要中的关键信息”。但在对话生成或创造性任务中，**Precision** 也很重要，以避免幻觉或无关内容。\n",
    "\n",
    "---\n",
    "\n",
    "### 四、补充说明\n",
    "\n",
    "- `use_stemmer=True`：对英文进行词干提取（如 \"running\" → \"run\"），提升匹配鲁棒性。\n",
    "- 支持多参考文本：可通过循环或取最大分处理多个 references。\n",
    "- ROUGE-L 虽基于 LCS，但仍以 **n-gram 风格**计算 P/R/F1：\n",
    "  - Precision = LCS_length / len(candidate)\n",
    "  - Recall = LCS_length / len(reference)\n",
    "  - F1 = 调和平均\n",
    "\n",
    "---\n",
    "\n",
    "### 总结\n",
    "\n",
    "| ROUGE 类型 | 匹配单元           | 侧重                     |\n",
    "|------------|--------------------|--------------------------|\n",
    "| ROUGE-1    | 单词（unigram）     | 词汇覆盖                 |\n",
    "| ROUGE-2    | 连续词对（bigram）  | 短语结构和局部词序       |\n",
    "| ROUGE-L    | 最长公共子序列（LCS）| 句子级结构，允许非连续但保序 |\n",
    "\n",
    "通过 `rouge_scorer` 获取的 **Precision、Recall、F1** 可全面评估生成文本：\n",
    "- **Recall** 衡量对参考内容的**覆盖能力**\n",
    "- **Precision** 衡量生成内容的**相关性**\n",
    "- **F1** 提供综合性能指标\n",
    "\n",
    "这使得 ROUGE 成为摘要、问答、标题生成等任务中不可或缺的自动评估工具。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1cdbe7",
   "metadata": {},
   "source": [
    "# 3、困惑度作为模型评估指标的意义是什么？解释困惑度计算的基本过程，并说明如何通过torch.exp和torch.nn.functional.cross_entropy函数计算模型在生成任务中的困惑度。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a66f97e",
   "metadata": {},
   "source": [
    "困惑度（Perplexity, PPL）是自然语言处理中广泛用于评估**语言模型**（Language Model）性能的核心指标，尤其在文本生成、机器翻译、语音识别等任务中具有重要意义。\n",
    "\n",
    "---\n",
    "\n",
    "### 一、困惑度的意义\n",
    "\n",
    "**困惑度衡量的是语言模型对测试数据的“惊讶程度”**：  \n",
    "- **值越低** → 模型对数据越“不困惑”，预测越准确，语言建模能力越强。  \n",
    "- **值越高** → 模型越“困惑”，说明其预测分布与真实数据分布差异较大。\n",
    "\n",
    "直观理解：  \n",
    "> 如果一个模型的困惑度为 20，意味着它在预测下一个词时，**等效于在一个平均包含 20 个等概率候选词的词表中随机选择**。\n",
    "\n",
    "因此，困惑度常被用作：\n",
    "- 语言模型训练过程中的验证指标；\n",
    "- 不同模型架构或超参数的比较基准；\n",
    "- 生成任务中模型“流畅性”和“一致性”的代理指标（尽管不直接衡量语义正确性）。\n",
    "\n",
    "---\n",
    "\n",
    "### 二、困惑度的计算原理\n",
    "\n",
    "困惑度基于**交叉熵损失**（Cross-Entropy Loss）定义：\n",
    "\n",
    "设测试集包含 ($ N $) 个词，模型对每个词 ($ w_i $) 的预测概率为 ($ P(w_i | w_{<i}) $)，则：\n",
    "\n",
    "1. **平均负对数似然（NLL）**：\n",
    "$\n",
    "\\text{NLL} = -\\frac{1}{N} \\sum_{i=1}^{N} \\log P(w_i | w_{<i})\n",
    "$\n",
    "\n",
    "2. **困惑度**：\n",
    "$\n",
    "\\text{Perplexity} = \\exp\\left( \\text{NLL} \\right) = \\exp\\left( -\\frac{1}{N} \\sum_{i=1}^{N} \\log P(w_i | w_{<i}) \\right)\n",
    "$\n",
    "\n",
    "即：**困惑度 = 交叉熵损失的指数**。\n",
    "\n",
    "---\n",
    "\n",
    "### 三、使用 PyTorch 计算困惑度\n",
    "\n",
    "在生成任务中（如 GPT 类模型），通常通过以下步骤计算 PPL：\n",
    "\n",
    "#### 1. 模型输入与输出\n",
    "- 输入：tokenized 文本序列 ($ x = [x_0, x_1, ..., x_{T-1}] $)\n",
    "- 目标：预测下一个词，即 ($ \\text{target} = [x_1, x_2, ..., x_T] $)\n",
    "- 模型输出：logits（未归一化的预测分数），形状为 ($ (T, V) $)，其中 ($ V $) 是词表大小\n",
    "\n",
    "#### 2. 计算交叉熵损失\n",
    "使用 `torch.nn.functional.cross_entropy`，它内部完成：\n",
    "- 对 logits 做 softmax 得到概率分布；\n",
    "- 计算负对数似然（NLL）；\n",
    "- 默认对所有位置取平均。\n",
    "\n",
    "#### 3. 困惑度 = `torch.exp(交叉熵损失)`\n",
    "\n",
    "#### 示例代码：\n",
    "\n",
    "```python\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 假设模型输出 logits 和真实标签\n",
    "# logits: [sequence_length, vocab_size]\n",
    "# labels: [sequence_length] （即 target tokens）\n",
    "\n",
    "logits = torch.randn(10, 5000)  # 10个token，词表大小5000\n",
    "labels = torch.randint(0, 5000, (10,))  # 真实下一个词的索引\n",
    "\n",
    "# 计算交叉熵损失（自动忽略 padding 可通过 ignore_index 实现）\n",
    "loss = F.cross_entropy(logits, labels, reduction='mean')  # scalar\n",
    "\n",
    "# 困惑度 = exp(平均交叉熵损失)\n",
    "perplexity = torch.exp(loss)\n",
    "\n",
    "print(f\"Loss: {loss.item():.4f}\")\n",
    "print(f\"Perplexity: {perplexity.item():.4f}\")\n",
    "```\n",
    "\n",
    "> ✅ 注意：`cross_entropy` 默认使用 `reduction='mean'`，即对所有 token 取平均，正好对应 NLL 的定义。\n",
    "\n",
    "#### 处理 batch 和 padding\n",
    "\n",
    "在实际训练/评估中，常需处理 batch 和 padding：\n",
    "\n",
    "```python\n",
    "# 假设 batch_size=2, max_len=10\n",
    "logits = torch.randn(2, 10, 5000)  # [B, T, V]\n",
    "labels = torch.randint(-1, 5000, (2, 10))  # -1 表示 padding\n",
    "\n",
    "# 忽略 padding token（如 -100 是 Hugging Face 默认的 ignore_index）\n",
    "loss = F.cross_entropy(\n",
    "    logits.view(-1, logits.size(-1)),   # [B*T, V]\n",
    "    labels.view(-1),                    # [B*T]\n",
    "    ignore_index=-100,\n",
    "    reduction='mean'\n",
    ")\n",
    "\n",
    "ppl = torch.exp(loss)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 四、注意事项\n",
    "\n",
    "1. **困惑度不能跨数据集直接比较**：受词表大小、数据分布影响。\n",
    "2. **不反映语义质量**：一个语法通顺但事实错误的句子可能有低 PPL。\n",
    "3. **仅适用于自回归语言模型**：如 GPT；对于 BERT 等掩码语言模型，需调整计算方式（如仅对 masked 位置计算）。\n",
    "4. **避免数值溢出**：若 loss 过大（如 > 100），`exp(loss)` 可能为 `inf`，需检查数据或模型。\n",
    "\n",
    "---\n",
    "\n",
    "### 总结\n",
    "\n",
    "| 组件 | 作用 |\n",
    "|------|------|\n",
    "| **交叉熵损失** | 衡量模型预测分布与真实标签的差异 |\n",
    "| **`torch.exp(loss)`** | 将 NLL 转换为困惑度 |\n",
    "| **`F.cross_entropy`** | 高效计算平均 NLL，支持 ignore_index 处理 padding |\n",
    "| **低 PPL** | 表示模型对语言建模更准确、更“自信” |\n",
    "\n",
    "因此，**困惑度 = `torch.exp(F.cross_entropy(logits, labels))`** 是评估生成模型语言建模能力的标准做法，广泛应用于研究和工程实践中。"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
