{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10b8c853",
   "metadata": {},
   "source": [
    "BLEU(Bilingual Evaluation Understudy)\n",
    "ROUGE(Recall-Oriented Understudy for Gisting Evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8d05c055",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from rouge_score import rouge_scorer\n",
    "import jieba\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3b3eceb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参考文本\n",
    "reference_text = \"近年来，随着人工智能技术的不断发展，深度学习和自然语言处理逐渐成为热门的研究领域，特别是在文本生成方面，GPT（Generative Pre-trained Transformer）模型表现出色，能够生成具有连贯性和逻辑性的长文本。GPT模型基于大规模的文本进行预训练，利用自注意力机制在生成过程中关注上下文信息，从而在各种应用场景中取得了显著的成果。例如，在智能客服系统中，GPT模型可以根据用户的问题生成合理的回答，提高了客服效率。此外，GPT模型在内容创作领域也展现出巨大的潜力，能够帮助创作者提供灵感，甚至生成整篇文章。\"\n",
    "generated_text = \"随着人工智能的发展，深度学习和自然语言处理成为研究的热点。GPT模型在文本生成任务中表现优异，能够生成连贯的长文本。GPT模型通过自注意力机制，利用上下文信息生成复合逻辑的文本，并在诸多领域取得显著成果。例如，智能客服系统利用GPT模型生成合理的回答，大大提高了服务效率。在内容创作中，GPT模型帮助创作者提供灵感，生成初步的内容。这种能力在未来将进一步推动人工智能在各个领域的应用。\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bf0b4fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BLEU分数计算\n",
    "def calculate_bleu(generated: str, reference: str):\n",
    "    ref_tokens = list(jieba.cut(reference))\n",
    "    gen_tokens = list(jieba.cut(generated))\n",
    "    print(\"Reference tokens:\", ref_tokens)\n",
    "    print(\"Generated tokens:\", gen_tokens)\n",
    "    print(\"Lengths - ref:\", len(ref_tokens), \"gen:\", len(gen_tokens))\n",
    "    bleu_score = sentence_bleu(\n",
    "        [ref_tokens], gen_tokens,\n",
    "        smoothing_function=SmoothingFunction().method1\n",
    "    )\n",
    "    return bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "de56c581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROUGE分数计算\n",
    "def calculate_rouge(generated: str, reference: str) -> dict:\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    scores = scorer.score(reference, generated)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "97ac9845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference tokens: ['近年来', '，', '随着', '人工智能', '技术', '的', '不断', '发展', '，', '深度', '学习', '和', '自然语言', '处理', '逐渐', '成为', '热门', '的', '研究', '领域', '，', '特别', '是', '在', '文本', '生成', '方面', '，', 'GPT', '（', 'Generative', ' ', 'Pre', '-', 'trained', ' ', 'Transformer', '）', '模型', '表现出色', '，', '能够', '生成', '具有', '连贯性', '和', '逻辑性', '的', '长', '文本', '。', 'GPT', '模型', '基于', '大规模', '的', '文本', '进行', '预', '训练', '，', '利用', '自', '注意力', '机制', '在', '生成', '过程', '中', '关注', '上下文', '信息', '，', '从而', '在', '各种', '应用', '场景', '中', '取得', '了', '显著', '的', '成果', '。', '例如', '，', '在', '智能', '客服', '系统', '中', '，', 'GPT', '模型', '可以', '根据', '用户', '的', '问题', '生成', '合理', '的', '回答', '，', '提高', '了', '客服', '效率', '。', '此外', '，', 'GPT', '模型', '在', '内容', '创作', '领域', '也', '展现出', '巨大', '的', '潜力', '，', '能够', '帮助', '创作者', '提供', '灵感', '，', '甚至', '生成', '整篇文章', '。']\n",
      "Generated tokens: ['随着', '人工智能', '的', '发展', '，', '深度', '学习', '和', '自然语言', '处理', '成为', '研究', '的', '热点', '。', 'GPT', '模型', '在', '文本', '生成', '任务', '中', '表现', '优异', '，', '能够', '生成', '连贯', '的', '长', '文本', '。', 'GPT', '模型', '通过', '自', '注意力', '机制', '，', '利用', '上下文', '信息', '生成', '复合', '逻辑', '的', '文本', '，', '并', '在', '诸多', '领域', '取得', '显著', '成果', '。', '例如', '，', '智能', '客服', '系统', '利用', 'GPT', '模型', '生成', '合理', '的', '回答', '，', '大大提高', '了', '服务', '效率', '。', '在', '内容', '创作', '中', '，', 'GPT', '模型', '帮助', '创作者', '提供', '灵感', '，', '生成', '初步', '的', '内容', '。', '这种', '能力', '在', '未来', '将', '进一步', '推动', '人工智能', '在', '各个领域', '的', '应用', '。']\n",
      "Lengths - ref: 134 gen: 104\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.23562135755175467"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_score = calculate_bleu(generated_text, reference_text)\n",
    "bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "efb27d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference tokens: ['你好', '呀', '哈哈哈', '哈哈哈', '哈哈哈', '哈哈哈']\n",
      "Generated tokens: ['你好', '呀', '哈哈哈', '哈哈哈', '哈哈哈', '哈哈哈']\n",
      "Lengths - ref: 6 gen: 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_score = calculate_bleu(\"你好呀哈哈哈哈哈哈哈哈哈哈哈哈\", \"你好呀哈哈哈哈哈哈哈哈哈哈哈哈\")\n",
    "bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5c29cf70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference tokens: ['你好', '呀']\n",
      "Generated tokens: ['你好', '呀']\n",
      "Lengths - ref: 2 gen: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.316227766016838"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_score = calculate_bleu(\"你好呀\", \"你好呀\")\n",
    "bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f834dd65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': Score(precision=1.0, recall=0.5, fmeasure=0.6666666666666666),\n",
       " 'rouge2': Score(precision=0.6666666666666666, recall=0.2857142857142857, fmeasure=0.4),\n",
       " 'rougeL': Score(precision=1.0, recall=0.5, fmeasure=0.6666666666666666)}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge_score = calculate_rouge(generated_text, reference_text)\n",
    "rouge_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4128705b",
   "metadata": {},
   "source": [
    "困惑度基于模型的预测概率分布，表示模型对下一个词的预测难度。\n",
    "- 困惑度越低，代表模型对生成任务的适应性越好，生成的文本越连贯。\n",
    "- 困惑度的计算通常通过模型输出的交叉墒损失计算，即计算预测词分布与真实标签之间的误差，再对损失值取对数。\n",
    "\n",
    "基于困惑度的优化过程中应注意的问题：\n",
    "- 困惑度越低，不总意味着文本质量高；困惑度衡量的是模型对文本的拟合程度，非生成内容的可读性或逻辑性。\n",
    "- 设置合理的学习率。可使用动态学习率。\n",
    "- 微调过程中防止过拟合。\n",
    "- 数据集质量要高，噪声多的数据集会影响模型的训练过程，导致困惑度偏高。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "349ab338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设的GPT模型，用于困惑度计算\n",
    "class SimpleGPTModel(nn.Module):\n",
    "    def __init__(self, voca_size, embedding_size):\n",
    "        super(SimpleGPTModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(voca_size, embedding_dim=embedding_size)\n",
    "        self.fc = nn.Linear(embedding_size, voca_size)\n",
    "    \n",
    "    def forward(self, input_ids):\n",
    "        output = self.embedding(input_ids)\n",
    "        output = self.fc(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7355f65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 困惑度计算\n",
    "class GPTPerplexityCalculator(nn.Module):\n",
    "    def __init__(self, model, vocab_size):\n",
    "        super(GPTPerplexityCalculator, self).__init__()\n",
    "        self.model = model\n",
    "        self.vocab_size = vocab_size\n",
    "    \n",
    "    def forward(self, input_ids):\n",
    "        output = self.model(input_ids)\n",
    "        logits = output.view(-1, self.vocab_size)\n",
    "        shift_labels = input_ids[:, 1:].contiguous().view(-1)\n",
    "        loss = F.cross_entropy(logits[:-1], shift_labels)\n",
    "        perplexity = torch.exp(loss)\n",
    "        return perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "eaedfd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型和假设输入\n",
    "vocab_size = 300\n",
    "embedding_size = 512\n",
    "model = SimpleGPTModel(voca_size=vocab_size, embedding_size=embedding_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4fc9cb54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(371.7115, grad_fn=<ExpBackward0>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 假设的输入\n",
    "input_data = torch.randint(0, vocab_size, (1, 100))\n",
    "# 计算困惑度\n",
    "perplexity_calculator = GPTPerplexityCalculator(model=model, vocab_size=vocab_size)\n",
    "perplexity = perplexity_calculator(input_data)\n",
    "perplexity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
