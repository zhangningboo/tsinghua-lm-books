{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20d253e8",
   "metadata": {},
   "source": [
    "### 层归一化 LayerNorm\n",
    "  - 是一种正则化方法\n",
    "  - 提高模型的训练稳定性\n",
    "  - 通过对每一层的输入进行标准化，使得网络中的每一层在训练过程中保持相对一致的分布\n",
    "  - 加速收敛\n",
    "  - 缓解梯度消失问题\n",
    "  - 在特征纬度上进行标准化\n",
    "  - 使用可学习的缩放参数和偏置参数进行调整\n",
    "  - 比BarchNorm更适合序列建模任务和小批量数据训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3decb454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7cd90cd4ef10>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(42) # 设置随机种子，保证每次运行结果一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d42a270d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义带归一化的神经网络层\n",
    "class LayerNormBlock(nn.Module):\n",
    "    def __init__(self, embedding_size):\n",
    "        super(LayerNormBlock, self).__init__()\n",
    "        self.layer_norm = nn.LayerNorm(embedding_size)\n",
    "        self.fc = nn.Linear(embedding_size, embedding_size)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer_norm(x)\n",
    "        out = self.fc(out)\n",
    "        out = self.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8be3bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建包含层归一化的简单网络模型\n",
    "class SimpleLayerNormModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_classes=10):\n",
    "        super(SimpleLayerNormModel, self).__init__()\n",
    "        self.layer1 = LayerNormBlock(input_dim)\n",
    "        self.layer2 = LayerNormBlock(hidden_dim)\n",
    "        self.layer3 = LayerNormBlock(hidden_dim)\n",
    "        self.fc_out = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.fc_out(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49fbd983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 10])\n"
     ]
    }
   ],
   "source": [
    "# 模拟输入数据\n",
    "input_data = torch.randn(32, 128)  # 批量大小为32，输入维度为128\n",
    "\n",
    "# 创建模型实例\n",
    "model = SimpleLayerNormModel(input_dim=128, hidden_dim=128, num_classes=10)\n",
    "\n",
    "# 前向传播\n",
    "output = model(input_data)\n",
    "print(output.shape)  # 输出形状应为 (32, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "550af966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b666452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模拟训练步骤\n",
    "targets = torch.randint(0, 10, (32,))  # 随机类别标签， 10个类别，批量大小32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae13e52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.318890333175659\n"
     ]
    }
   ],
   "source": [
    "optimizer.zero_grad()\n",
    "loss = criterion(output, targets)\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "print(f\"Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d524139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer1.layer_norm.weight - mean: 1.0000, std: 0.0010\n",
      "layer1.layer_norm.bias - mean: 0.0001, std: 0.0010\n",
      "layer2.layer_norm.weight - mean: 1.0000, std: 0.0010\n",
      "layer2.layer_norm.bias - mean: -0.0002, std: 0.0010\n",
      "layer3.layer_norm.weight - mean: 0.9999, std: 0.0010\n",
      "layer3.layer_norm.bias - mean: -0.0001, std: 0.0010\n"
     ]
    }
   ],
   "source": [
    "# 归一化层参数更新情况\n",
    "for name, param in model.named_parameters():\n",
    "    if 'layer_norm' in name:\n",
    "        print(f\"{name} - mean: {param.data.mean():.4f}, std: {param.data.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ddea741c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试数据的网络输出: torch.Size([32, 10])\n"
     ]
    }
   ],
   "source": [
    "# 测试模型在不同输入分布下的稳定性\n",
    "test_input = torch.randn(32, 128) * 10 + 50  # 不同分布的输入\n",
    "test_output = model(test_input)\n",
    "print(\"测试数据的网络输出:\", test_output.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "frome_zero_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
