{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d40ff85",
   "metadata": {},
   "source": [
    "### 掩码语言模型MLM： 是BERT模型的核心预训练任务。通过在输入文本中随机遮掩部分词语并让模型预测这些词，模型能够有效地学习词的上下文语义。"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
